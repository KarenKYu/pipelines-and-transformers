{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers and Pipelines Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll practice using transformers and pipelines to coerce our data.  We'll walk through some additional features of pipelines in sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "housing_df = pd.read_csv('./kc_house_data_missing_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7740 entries, 0 to 7739\n",
      "Data columns (total 7 columns):\n",
      "id             7740 non-null int64\n",
      "date           7740 non-null object\n",
      "price          7740 non-null float64\n",
      "bedrooms       7740 non-null int64\n",
      "bathrooms      7740 non-null float64\n",
      "sqft_living    7740 non-null int64\n",
      "floors         7662 non-null float64\n",
      "dtypes: float64(3), int64(3), object(1)\n",
      "memory usage: 423.4+ KB\n"
     ]
    }
   ],
   "source": [
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with using some of our transformers.  We'll start with the SimpleImputer.  Remember that this will allow us to replace our missing values with the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select the `floors` column as it currently has missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "floors = housing_df[['floors']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by loading the SimpleImputer from the `impute` module, and then initialize a new imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "              missing_values=nan, strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer\n",
    "# SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
    "#               missing_values=nan, strategy='mean', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the imputer is initialized with some default arguments.  For example, we see that we can replace our missing values in floors with the mean.  \n",
    "\n",
    "First, we learn what the mean is, by fitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "              missing_values=nan, strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.fit(floors)\n",
    "\n",
    "# SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
    "#               missing_values=nan, strategy='mean', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can check that this worked by looking at the mean, captured in the `statistics_` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.61243801])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.statistics_\n",
    "# array([1.61243801])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we transform the data, with the `transform` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_floors = imputer.transform(floors)\n",
    "transformed_floors[:3]\n",
    "\n",
    "# array([[2.],\n",
    "#        [1.],\n",
    "#        [1.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Practice with Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now oftentimes, we use transformers so that we can apply the same transformations to both our training and holdout datasets, as well as any future data.  \n",
    "\n",
    "Let's see this in practice by sorting our dataset by `date` and then splitting our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_housing_df = housing_df.sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>floors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6354</th>\n",
       "      <td>3396800120</td>\n",
       "      <td></td>\n",
       "      <td>540000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2180</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>9547205660</td>\n",
       "      <td></td>\n",
       "      <td>603000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1700</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id date     price  bedrooms  bathrooms  sqft_living  floors\n",
       "6354  3396800120       540000.0         3       2.50         2180     1.0\n",
       "831   9547205660       603000.0         3       2.25         1700     2.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_housing_df[:2]\n",
    "\n",
    "# \tid\tdate\tprice\tbedrooms\tbathrooms\tsqft_living\tfloors\n",
    "# 6354\t3396800120\t\t540000.0\t3\t2.50\t2180\t1.0\n",
    "# 831\t9547205660\t\t603000.0\t3\t2.25\t1700\t2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign `X` to equal every feature except `price`, `id` and `date`, and set `y` to equal price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sorted_housing_df.drop(columns = ['id', 'price', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sorted_housing_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>floors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6354</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2180</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1700</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bedrooms  bathrooms  sqft_living  floors\n",
       "6354         3       2.50         2180     1.0\n",
       "831          3       2.25         1700     2.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2]\n",
    "\n",
    "\n",
    "# \tbedrooms\tbathrooms\tsqft_living\tfloors\n",
    "# 6354\t3\t2.50\t2180\t1.0\n",
    "# 831\t3\t2.25\t1700\t2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6354    540000.0\n",
       "831     603000.0\n",
       "5565    965800.0\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:3]\n",
    "\n",
    "# 6354    540000.0\n",
    "# 831     603000.0\n",
    "# 5565    965800.0\n",
    "# Name: price, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's split our data using `train_test_split` placing `20` percent of our data in the test dataset.  \n",
    "\n",
    "> Make sure to set shuffle equal to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>floors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6354</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2180</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1700</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bedrooms  bathrooms  sqft_living  floors\n",
       "6354         3       2.50         2180     1.0\n",
       "831          3       2.25         1700     2.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]\n",
    "# \tbedrooms\tbathrooms\tsqft_living\tfloors\n",
    "# 6354\t3\t2.50\t2180\t1.0\n",
    "# 831\t3\t2.25\t1700\t2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's go back to transformers.  This time we'll use the `StandardScaler`.  Import `StandardScaler`from the `preprocessing` library, and then initialize the new StandardScaler.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this time we'll apply the transformer to more than one column.  We'll do so by fitting with our `X_train` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can see the learned means with the `mean_` method.  Note that it learned a different mean for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.58552972e+00, 2.33570198e+00, 2.41132214e+03, 1.61196239e+00])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.32779414e-01, 4.43753362e-01, 5.95523995e+05, 2.83651085e-01])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.var_\n",
    "# array([9.32779414e-01, 4.43753362e-01, 5.95523995e+05, 2.83651085e-01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the scaler to transform the `X_train` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.60626077,  0.24663886, -0.29975578, -1.14903301],\n",
       "       [-0.60626077, -0.12865303, -0.92175752,  0.7285873 ],\n",
       "       [ 0.42914487, -0.87923682,  0.11491205, -1.14903301]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_X_train = scaler.transform(X_train)\n",
    "\n",
    "transformed_X_train[:3]\n",
    "# array([[-0.60626077,  0.24663886, -0.29975578, -1.14903301],\n",
    "#        [-0.60626077, -0.12865303, -0.92175752,  0.7285873 ],\n",
    "#        [ 0.42914487, -0.87923682,  0.11491205, -1.14903301]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So notice that we can use the transformers to change multiple features at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now let's transform the `X_test` data using the same parameters we found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.60626077, -0.12865303, -0.96063263,  0.7285873 ],\n",
       "       [-1.6416664 , -2.00511249, -0.94767426, -1.14903301],\n",
       "       [-0.60626077, -2.00511249, -1.18092492, -1.14903301]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_test[:3]\n",
    "# array([[-0.60626077, -0.12865303, -0.96063263,  0.7285873 ],\n",
    "#        [-1.6416664 , -2.00511249, -0.94767426, -1.14903301],\n",
    "#        [-0.60626077, -2.00511249, -1.18092492, -1.14903301]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we often fit and then transform a dataset, we can combine these two procedures in one method - `fit_transform`.  Let's show how it's done.  \n",
    "\n",
    "If we wish to scale our `X_train` data, and then apply the same changes to the `X_test` data, we'll do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.60626077,  0.24663886, -0.29975578, -1.14903301],\n",
       "       [-0.60626077, -0.12865303, -0.92175752,  0.7285873 ],\n",
       "       [ 0.42914487, -0.87923682,  0.11491205, -1.14903301]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled[:3]\n",
    "# array([[-0.60626077,  0.24663886, -0.29975578, -1.14903301],\n",
    "#        [-0.60626077, -0.12865303, -0.92175752,  0.7285873 ],\n",
    "#        [ 0.42914487, -0.87923682,  0.11491205, -1.14903301]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this method above both fitted to the data, and then returned the transformed array of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.58552972e+00, 2.33570198e+00, 2.41132214e+03, 1.61196239e+00])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the scaler has been fit, we can apply the same changes to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.60626077, -0.12865303, -0.96063263,  0.7285873 ],\n",
       "       [-1.6416664 , -2.00511249, -0.94767426, -1.14903301]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_X_test[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that we do not need to call `fit` on the test data.  In fact it would be a mistake to do so.  This is because, the goal is to provide the same transformations to both datasets.  This way, when we train our model on the transformed `X_train` data, we can then test the model on holdout sets that have been transformed the same way.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers and Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note is that transformers only work with two dimensional data.  If we try to select a column as a one dimensional array, we get an error both with the `fit` method and the `transform` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.60626077, -0.60626077,  0.42914487, ...,  0.42914487,\n",
       "        0.42914487, -0.60626077])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_dim_X_train =  transformed_X_train[:, 0]\n",
    "single_dim_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Uncomment and recomment the line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler.transform(single_dim_X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we learned about the interface for pandas transformers.  We saw that the transformers have us first `fit`, whereby they learn the transformation, and `transform`, where the transformation is applied. \n",
    "\n",
    "One way that transformers assist us, is by allowing us to make the same transformations to different dataset.  We do this, simply by reusing our transformer and calling `transform` on a different dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
